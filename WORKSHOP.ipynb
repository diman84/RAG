{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load documents from GIT Repository\n",
    "Langchain `DocumentLoaders` load data into the standard LangChain `Document` format. We can use components provided by langchain or any custom loader implementing `DocumentLoader` interface.\n",
    "\n",
    "Some of available loaders in [langchain_community.document_loaders](https://python.langchain.com/docs/integrations/document_loaders/):\n",
    "- **Webpages**: allow you to load webpages.\n",
    "- **PDFs**: allow you to load PDF documents.\n",
    "- **Cloud Providers**: allow you to load documents from your favorite cloud providers.\n",
    "- **Tools**: allow you to load data from commonly used tools like Slack, Quip, Github and more..\n",
    "- **Local**: allow you to load data from your local file system.\n",
    "\n",
    "In order to load files from GIT repository we can use `GitLoader` community package that will allow to load reposiitory data, where each document would represent one file in the repository.\n",
    "\n",
    "We can also utilize `GitPython` package to clone repository and retreive another useful information.\n",
    "\n",
    "```\n",
    "> pip install --upgrade --quiet  GitPython\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "from git import Repo\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import GitLoader\n",
    "\n",
    "jsLoader = GitLoader(repo_path=\"./local-repository/\", branch='master', file_filter=lambda file_path: file_path.endswith(\".js\"))\n",
    "mdLoader = GitLoader(repo_path=\"./local-repository/\", branch='master', file_filter=lambda file_path: file_path.endswith(\".md\"))\n",
    "defaultLoader = GitLoader(repo_path=\"./local-repository/\", branch='master', file_filter=lambda file_path: not file_path.endswith(\".md\") and not file_path.endswith(\".js\"))\n",
    "\n",
    "jsData = jsLoader.load()\n",
    "mdData = mdLoader.load()\n",
    "otherData = defaultLoader.load()\n",
    "\n",
    "print(len(jsData))\n",
    "print(len(mdData))\n",
    "print(len(otherData))\n",
    "\n",
    "#print(mdData[0])\n",
    "#print(jsData[1])\n",
    "#print(otherData[3])\n",
    "\n",
    "repo = Repo(\"./local-repository/\")\n",
    "def get_changed_files():\n",
    "    changed_files = []\n",
    "    diff_index = repo.index.diff(None)\n",
    "    for diff_item in diff_index:\n",
    "        changed_files.append(diff_item.a_path)\n",
    "\n",
    "    return changed_files\n",
    "\n",
    "def get_commits_from_branch(branch_name):\n",
    "    branch = next(filter(lambda b: b.name == branch_name, repo.branches), None)\n",
    "    if (branch is not None):        \n",
    "        commits = list(branch.commit.iter_items(repo, branch.commit))    \n",
    "        return [commit.message for commit in commits]\n",
    "    ref = next(filter(lambda b: b.name == f\"origin/{branch_name}\", repo.remote().refs), None)\n",
    "    if ref is not None:        \n",
    "        commits = list(repo.iter_commits(ref))    \n",
    "        return [commit.message for commit in commits]    \n",
    "    return []\n",
    "\n",
    "def load_commits() -> Iterator[Document]:\n",
    "    for commit in repo.iter_commits():\n",
    "        metadata = {\n",
    "            \"commit_author_name\": commit.author.name,\n",
    "            \"commit_author_email\": commit.author.email,\n",
    "            \"commit_authored_datetime\": commit.authored_datetime,\n",
    "            \"commit_committed_datetime\": commit.committed_datetime,\n",
    "        }\n",
    "        yield Document(page_content=commit.message, metadata=metadata)\n",
    "\n",
    "commits_data = list(load_commits())\n",
    "\n",
    "print(len(commits_data))\n",
    "#print(commitsData[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and Split documents into chunks\n",
    "\n",
    "There are different ways to split a document into chunks, the most challenging part that we need to consider is to split the document into meaningful chunks, and it can strongly depend on the document type and the use case.\n",
    "\n",
    "In our case there are 3 types of documents we can consider:\n",
    "  - **Text documents**: We can split the text into paragraphs, sentences, or words.\n",
    "  - **Code documents**: We can split the code into functions, classes, or lines.\n",
    "  - **Git data**: We can split the git data into commits, files, or lines.\n",
    "\n",
    "Splitters supported by [langchain.text_splitter](https://python.langchain.com/v0.2/api_reference/text_splitters/index.html) that we can use:\n",
    "  - **RecursiveCharacterTextSplitter**: Implementation of splitting text that recursively looks at characters.\n",
    "  - **MarkdownHeaderTextSplitter**: Implementation of splitting markdown files based on specific headers.\n",
    "  - **TokenTextSplitter**: Implementation of splitting text that looks at tokens.\n",
    "  - **SentenceTransformersTokenTextSplitter**: It is a specialized text splitter for use with the sentence-transformer models. The default behaviour is to split the text into chunks that fit the token window of the sentence transformer model that you would like to use.\n",
    "  - **RecursiveJsonSplitter**: Implementation of splitting text that looks at characters. Recursively tries to split by different characters to find the one that works.\n",
    "  - **Language**: for CPP, Python, Ruby, etc...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, MarkdownTextSplitter, Language, TokenTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "\n",
    "js_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.JS, chunk_size=100, chunk_overlap=0\n",
    ")\n",
    "md_splitter = MarkdownTextSplitter(chunk_size=100, chunk_overlap=10)\n",
    "token_splitter = TokenTextSplitter(chunk_size=100, chunk_overlap=10)\n",
    "sentence_splitter = SentenceTransformersTokenTextSplitter()\n",
    "\n",
    "js_docs = js_splitter.split_documents(jsData)\n",
    "md_docs = md_splitter.split_documents(mdData)\n",
    "other_docs = token_splitter.split_documents(otherData)\n",
    "commit_docs = sentence_splitter.split_documents(commits_data)\n",
    "\n",
    "\n",
    "print(len(commit_docs))\n",
    "print(len(js_docs))\n",
    "print(len(md_docs))\n",
    "print(len(other_docs))\n",
    "\n",
    "#print(js_docs[0])\n",
    "#print(md_docs[0])\n",
    "#print(other_docs[0])\n",
    "#print(commit_docs[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embedding vectors\n",
    "\n",
    "Embeddings are essential for LLM tasks, they are high-dimensional vectors that capture the semantic meaning of tokens in chunks. We will use them for document corpus and for the query to search for relevant chunks that will be included into the context to generate completions.\n",
    "\n",
    "From this point we need to find a structure of contextual query to find proper documents for suggestion. Lets assume it will be changes in the code of current document. We can use `GitPython` to get the changes in the repository and use them as a query.\n",
    "\n",
    "To understand embeddings and how they aligned you can play with text embeddings in Cohere Playground (https://dashboard.cohere.com/playground/embed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import numpy\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sbertEmb = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# transformer = models.Transformer(\"sentence-transformers/all-MiniLM-L6-v2\", max_seq_length=256)\n",
    "# pooling = models.Pooling(transformer.get_word_embedding_dimension(), pooling_mode=\"mean\")\n",
    "# normalize = models.Normalize()\n",
    "# model = SentenceTransformer(modules=[transformer, pooling, normalize])\n",
    "\n",
    "openAIEmb = OpenAIEmbeddings(api_key=\"OPENAI_API_KEY\")\n",
    "hfEmb = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2') #sentence-transformers/all-mpnet-base-v2\n",
    "ollamaEmb = OllamaEmbeddings(model=\"llama3.2:1b\")\n",
    "starCoderEmb = OllamaEmbeddings(model=\"starcoder2:3b\")\n",
    "\n",
    "(js_embeddings, md_embeddings) = await asyncio.gather(\n",
    "    openAIEmb.aembed_documents([doc.page_content for doc in js_docs]),\n",
    "    ollamaEmb.aembed_documents([doc.page_content for doc in md_docs])\n",
    "    )\n",
    "\n",
    "commit_embeddings = sbertEmb.encode([doc.page_content for doc in commit_docs], convert_to_tensor=True) # hfEmb.embed_documents(md_docs)\n",
    "\n",
    "print(len(js_embeddings))\n",
    "print(len(md_embeddings))\n",
    "print(len(commit_embeddings))\n",
    "\n",
    "# print vector dimensions\n",
    "print(len(js_embeddings[0]))\n",
    "print(len(md_embeddings[0]))\n",
    "print(commit_embeddings.shape)\n",
    "\n",
    "# understanding embeddings\n",
    "# https://dashboard.cohere.com/playground/embed\n",
    "# mother, father, aunt, uncle\n",
    "plur = numpy.subtract(openAIEmb.embed_query(\"students\"), openAIEmb.embed_query(\"student\"))\n",
    "\n",
    "print(numpy.dot(plur, openAIEmb.embed_query(\"cat\")))\n",
    "print(numpy.dot(plur, openAIEmb.embed_query(\"cats\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data to Vector DB\n",
    "Vector DBs are very diverse, they support different types of embedding models and different types of search and API capabilities. Most of them support `langchain` models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple In-Memory\n",
    "# Chroma\n",
    "# Faiss\n",
    "# Qdrant\n",
    "\n",
    "import faiss\n",
    "import uuid\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "in_memory_vector_store = InMemoryVectorStore(openAIEmb)\n",
    "\n",
    "faiss_vec_dim = commit_embeddings.shape[1] # vector size of size of sentence-BERT embeddings\n",
    "faiss_index = faiss.IndexFlatL2(faiss_vec_dim)\n",
    "faiss_index.train(commit_embeddings)\n",
    "faiss_vector_store = FAISS(\n",
    "    embedding_function=hfEmb,\n",
    "    index=faiss_index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "\n",
    "client = QdrantClient(\":memory:\")\n",
    "client.create_collection(\n",
    "    collection_name=\"text_collection\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE), # 1536 - vector size of 'text-embedding-ada-002' OpenAI embeddings\n",
    ")\n",
    "client.create_collection(\n",
    "    collection_name=\"text_collection_hf\",\n",
    "    vectors_config=VectorParams(size=768, distance=Distance.COSINE), # 768 - vector size of SBERT embeddings\n",
    ")\n",
    "client.create_collection(\n",
    "    collection_name=\"code_collection\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE), # 1536 - vector size of 'text-embedding-ada-002' OpenAI embeddings\n",
    ")\n",
    "client.create_collection(\n",
    "    collection_name=\"code_collection_sc\",\n",
    "    vectors_config=VectorParams(size=3072, distance=Distance.COSINE), # 3072 - default vector size of starcoder2 embeddings\n",
    ")\n",
    "client.create_collection(\n",
    "    collection_name=\"docs_collection\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE), # 1536 - vector size of 'text-embedding-ada-002' OpenAI embeddings\n",
    ")\n",
    "client.create_collection(\n",
    "    collection_name=\"generic_collection_hf_384\",\n",
    "    vectors_config=VectorParams(size=384, distance=Distance.COSINE), # 384 - vector size of sentence-transformers/all-MiniLM-L6-v2 embeddings\n",
    ")\n",
    "qdrant_vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"docs_collection\",\n",
    "    embedding=openAIEmb, #ollamaEmb\n",
    ")\n",
    "\n",
    "# Add documents to the vector stores\n",
    "in_memory_vector_store.add_documents(documents=js_docs)\n",
    "\n",
    "qdrant_vector_store.add_documents(documents=md_docs)\n",
    "\n",
    "uuids = [str(uuid.uuid4()) for _ in range(len(commit_docs))]\n",
    "faiss_vector_store.add_documents(documents=commit_docs, ids=uuids)\n",
    "# FAISS.from_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search vectorized data\n",
    "In `Langchain`, components that are responsible to returns documents given an unstructured query ara called `Retreivers`, responsible for finding the most relevant documents along with its \"relativity\" to the query if possible.\n",
    "\n",
    "Retreivers, availabl for `langchain` integration can be found here https://python.langchain.com/docs/integrations/retrievers/ along with the usage guide https://python.langchain.com/docs/how_to/#retrievers\n",
    "\n",
    "We will start from vectorized data search capabilities based on vector store-backed retriever and search specific to certain types of stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from sentence_transformers import SimilarityFunction\n",
    "from sentence_transformers import util\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "current_diff = repo.git.diff()\n",
    "#print(current_diff)\n",
    "\n",
    "js_retriever = in_memory_vector_store.as_retriever(k=3) # similarity, mmf, scored similarity\n",
    "# js_retriever = in_memory_vector_store.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.5}, k=1)\n",
    "similar_js_docs = js_retriever.invoke(current_diff)\n",
    "print(\"similar js docs\")\n",
    "print(similar_js_docs)\n",
    "\n",
    "# summarize current diff to search info in commits\n",
    "chat = ChatOpenAI(model=\"gpt-4o-mini\", api_key=\"OPENAI_API_KEY\")\n",
    "summary_template = ChatPromptTemplate.from_template(\"Create short meaningful commit message of git diff.\\n{git_diff}\")\n",
    "# Try FewShotChatMessagePromptTemplate with example prompts\n",
    "summary_chain = summary_template | chat | StrOutputParser()\n",
    "summary = summary_chain.invoke({\"git_diff\":current_diff})\n",
    "print(f\"summary: {summary}\")\n",
    "\n",
    "# similarity search by query, vector and score\n",
    "summary_embeddings = hfEmb.embed_query(summary)\n",
    "similar_commits = faiss_vector_store.similarity_search_by_vector(summary_embeddings) # ANN search\n",
    "print(\"FAISS similar commits\")\n",
    "print(similar_commits)\n",
    "\n",
    "similar_commits_score = faiss_vector_store.similarity_search_with_score(summary, k=2)\n",
    "print(\"FAISS similar commits with score\")\n",
    "for (doc, score) in similar_commits_score:\n",
    "    print(f\"[{score}] {doc.page_content}\")\n",
    "\n",
    "remote_commits = get_commits_from_branch(\"with_router\")\n",
    "\n",
    "# SBERT smantic search (ENN search)\n",
    "# Select model depending on Symmetric vs Asymmetric Semantic Search\n",
    "sbertEmb.similarity_fn_name = SimilarityFunction.DOT_PRODUCT # SimilarityFunction.COSINE, etc.\n",
    "# model processing options can be cpu or gpu\n",
    "# convert_to_tensor=True\" is used to keep the tensors on GPU (if available)\n",
    "commits_emb = sbertEmb.encode(remote_commits, convert_to_tensor=True)\n",
    "summary_emb = sbertEmb.encode([summary], convert_to_tensor=True)\n",
    "commit_similarities = sbertEmb.similarity(summary_emb, commits_emb)[0] # pairwise_similarity\n",
    "scores, indices = torch.topk(commit_similarities, k=2)\n",
    "print(\"SBERT similar commits\")\n",
    "for score, idx in zip(scores, indices):\n",
    "    print(f\"[{score:.4f}] {remote_commits[idx]}\".rstrip())\n",
    "\n",
    "# speed optimization\n",
    "# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "#sbertEmbGpu = SentenceTransformer('all-MiniLM-L6-v2', device=\"cuda\")\n",
    "#commits_emb_gpu = sbertEmb.encode(remote_commits, convert_to_tensor=True).to(\"cuda\")\n",
    "#commits_emb_gpu = util.normalize_embeddings(commits_emb_gpu) # ENN\n",
    "#summary_emb_gpu = summary_emb.to(\"cuda\")\n",
    "#summary_emb_gpu = util.normalize_embeddings(summary_emb_gpu)\n",
    "#hits = util.semantic_search(summary_emb_gpu, commits_emb_gpu, score_function=util.dot_score)\n",
    "#print(\"GPU similar commits\")\n",
    "#print(hits)\n",
    "\n",
    "# FAISS specific search with performance improvements\n",
    "new_index = faiss.IndexIVFFlat(faiss_index, commit_embeddings.shape[1], 2)\n",
    "new_index.train(commit_embeddings)\n",
    "new_index.add(commit_embeddings)\n",
    "#d,i = new_index.search(summary_emb, k=1)\n",
    "print(\"FAISS specific search\")\n",
    "#print(i)\n",
    "\n",
    "# understanding relevance, score\n",
    "qdrant_test_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"text_collection\",\n",
    "    embedding=openAIEmb\n",
    ")\n",
    "\n",
    "qdrant_test_store.add_texts([\"She deposited money at the bank.\",\"The boat was tied to the river bank.\"])\n",
    "\n",
    "bank_relevance = qdrant_test_store.similarity_search_with_relevance_scores(\"steep bank\")\n",
    "bank_score = qdrant_test_store.similarity_search_with_score(\"steep bank\")\n",
    "\n",
    "print(bank_relevance)\n",
    "print(bank_score)\n",
    "\n",
    "bank_relevance = qdrant_test_store.similarity_search_with_relevance_scores(\"reliable bank\")\n",
    "bank_score = qdrant_test_store.similarity_search_with_score(\"reliable bank\")\n",
    "\n",
    "print(bank_relevance)\n",
    "print(bank_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reveal what we can get from Maximal Marginal Relevance (MMR) and how it can be used to improve search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain.chains.qa_with_sources.retrieval import RetrievalQAWithSourcesChain\n",
    "\n",
    "qdrant_code_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"code_collection\",\n",
    "    embedding=openAIEmb\n",
    ")\n",
    "\n",
    "# MMR example\n",
    "# Base code snippets with slight variations\n",
    "BASE_SNIPPET_0 = \"\"\"\n",
    "def add_numbers(a, b):\n",
    "    return a + b  # Adds two numbers\n",
    "\"\"\"\n",
    "\n",
    "BASE_SNIPPET_1 = \"\"\"\n",
    "def sum_values(x, y):\n",
    "    result = x + y  # Returns the sum of two values\n",
    "    return result\n",
    "\"\"\"\n",
    "\n",
    "BASE_SNIPPET_2 = \"\"\"\n",
    "def calculate_sum(num1, num2):\n",
    "    total = num1 + num2\n",
    "    return total  # Returns total of num1 and num2\n",
    "\"\"\"\n",
    "\n",
    "BASE_SNIPPET_3 = \"\"\"\n",
    "def add_two_values(value1, value2):\n",
    "    return value1 + value2  # Adding two numbers together\n",
    "\"\"\"\n",
    "\n",
    "# A snippet with a slightly different functionality\n",
    "DIFFERENT_SNIPPET = \"\"\"\n",
    "def multiply_numbers(x, y):\n",
    "    return x * y  # Multiplies two numbers\n",
    "\"\"\"\n",
    "\n",
    "# Insert into index\n",
    "code_snippets = [\n",
    "    BASE_SNIPPET_0,\n",
    "    BASE_SNIPPET_1,\n",
    "    BASE_SNIPPET_2,\n",
    "    BASE_SNIPPET_3,\n",
    "    DIFFERENT_SNIPPET,\n",
    "]\n",
    "metadatas = [\n",
    "    {\"source\": \"Common Python Utilities\"},\n",
    "    {\"source\": \"Common Python Utilities\"},\n",
    "    {\"source\": \"Common Python Utilities\"},\n",
    "    {\"source\": \"Common Python Utilities\"},\n",
    "    {\"source\": \"Mathematical Operations Module\"},\n",
    "]\n",
    "\n",
    "qdrant_code_store.add_texts(code_snippets, metadatas=metadatas)\n",
    "\n",
    "QUESTION = \"How do I perform basic arithmetic operations in Python? Use one sentence with function reference.\"\n",
    "\n",
    "retriever_sim = qdrant_code_store.as_retriever(search_type=\"similarity\", search_kwargs={ \"k\": 2})\n",
    "\n",
    "qa_chain_sim = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    chat,\n",
    "    retriever=retriever_sim,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "result = qa_chain_sim({\"question\": QUESTION})\n",
    "\n",
    "print(\"Similarity-based chain:\")\n",
    "print(\"Answer:\", result['answer'].strip())\n",
    "print(\"Sources:\", result['sources'].strip())\n",
    "\n",
    "retriever_mmr = qdrant_code_store.as_retriever(search_type=\"mmr\", search_kwargs={ \"k\": 2})\n",
    "\n",
    "# \n",
    "qa_chain_mmr = qa_chain_sim = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    chat,\n",
    "    retriever=retriever_mmr,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "result = qa_chain_mmr({\"question\": QUESTION})\n",
    "\n",
    "print(\"\\nMMR-based chain:\")\n",
    "print(\"Answer:\", result['answer'].strip())\n",
    "print(\"Sources:\", result['sources'].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try more examplew with code similarity search, trying to analyze multi modal codebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_sitter_languages import get_parser\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "# code similarity\n",
    "sort = \"\"\"\n",
    "void f(int[] array) {\n",
    "    boolean swapped = true;\n",
    "    for (int i = 0; i < array.length && swapped; i++) {\n",
    "        swapped = false;\n",
    "        for (int j = 0; j < array.length - 1 - i; j++) {\n",
    "           if (array[j] > array[j+1]) {\n",
    "               int temp = array[j];\n",
    "               array[j] = array[j+1];\n",
    "               array[j+1]= temp;\n",
    "               swapped = true;\n",
    "           }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "stddev = \"\"\"\n",
    "const f = (trials, len) => {\n",
    "    let sum = 0;\n",
    "    let squ = 0.0;\n",
    "\n",
    "    for (let i = 0; i < len; i++) {\n",
    "        let d = trials[i];\n",
    "        sum += d;\n",
    "        squ += d * d;\n",
    "    }\n",
    "\n",
    "    let x = squ - (sum * sum) / len;\n",
    "    let res = Math.sqrt(x / (len - 1));\n",
    "\n",
    "    return Math.floor(res);\n",
    "};\n",
    "\"\"\"\n",
    "\n",
    "indexOf = \"\"\"\n",
    "function f(array, value) {\n",
    "    for (let i = 0; i < array.length; i++) {\n",
    "        if (array[i] === value) {\n",
    "            return i;\n",
    "        }\n",
    "    }\n",
    "    return -1;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "sql_query = \"SELECT * FROM customers WHERE city = 'Berlin'\"\n",
    "\n",
    "qdrant_code_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"code_collection_sc\",\n",
    "    embedding=starCoderEmb\n",
    ")\n",
    "\n",
    "qdrant_code_store.add_texts(\n",
    "    [sort, stddev, indexOf],\n",
    "    metadatas=[{\"source\": \"sort\"}, {\"source\": \"stddev\"}, {\"source\": \"indexOf\"}],\n",
    ")\n",
    "\n",
    "qdrant_ast_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"code_collection\",\n",
    "    embedding=openAIEmb\n",
    ")\n",
    "\n",
    "sort_relevance = qdrant_code_store.similarity_search_with_relevance_scores(\"sort\")\n",
    "sort_score = qdrant_code_store.similarity_search_with_score(\"sort\")\n",
    "\n",
    "print(\"Code similarity with starcoder2 embeddings\")\n",
    "print(sort_relevance)\n",
    "print(sort_score)\n",
    "\n",
    "sql_relevance = qdrant_code_store.similarity_search_with_relevance_scores(sql_query)\n",
    "sql_score = qdrant_code_store.similarity_search_with_score(sql_query)\n",
    "\n",
    "print(\"SQL Code similarity with starcoder2 embeddings\")\n",
    "print(sql_relevance)\n",
    "print(sql_score)\n",
    "\n",
    "# code similarity with tree-sitter AST\n",
    "js_parser = get_parser('javascript')\n",
    "sql_parser = get_parser('sql')\n",
    "java_parser = get_parser('java')\n",
    "\n",
    "ts_query = sql_parser.parse(sql_query.encode()).root_node.sexp()\n",
    "\n",
    "ts_indexOf = js_parser.parse(indexOf.encode()).root_node.sexp()\n",
    "ts_stdev = js_parser.parse(stddev.encode()).root_node.sexp()\n",
    "ts_sort = java_parser.parse(sort.encode()).root_node.sexp()\n",
    "\n",
    "qdrant_ast_store.add_documents([\n",
    "    Document(page_content=ts_sort, metadata={'source':'ts_sort', 'source_code': sort, 'language':'java'}), \n",
    "    Document(page_content=ts_stdev, metadata={'source':'ts_stdev', 'source_code': stddev, 'language':'js'}), \n",
    "    Document(page_content=ts_indexOf, metadata={'source':'ts_indexOf', 'source_code': indexOf, 'language':'js'})])\n",
    "\n",
    "ts_relevance = qdrant_ast_store.similarity_search_with_relevance_scores(ts_query)\n",
    "ts_score = qdrant_ast_store.similarity_search_with_score(ts_query)\n",
    "print(ts_relevance)\n",
    "print(ts_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use text search approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from rank_bm25 import BM25Okapi\n",
    "#from sklearn.feature_extraction import _stop_words\n",
    "\n",
    "# Tokenization\n",
    "\n",
    "# use BM25Retriever to find similar commits\n",
    "bm25_results = BM25Retriever.from_texts(remote_commits).invoke(summary)\n",
    "print(\"Search in:\", remote_commits)\n",
    "print(\"BM25 similar commits for summary:\", summary)\n",
    "print(bm25_results)\n",
    "\n",
    "#https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-tokenizers.html\n",
    "def ngram_tokenizer(text, n=2):\n",
    "    text = text.strip(string.punctuation)\n",
    "    text = text.strip(string.whitespace)\n",
    "    tokens = list(text)\n",
    "    \n",
    "    # Generate the n-grams\n",
    "    ngrams_list = [' '.join(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "    \n",
    "    # Convert to a set to ensure uniqueness and return\n",
    "    return set(ngrams_list)\n",
    "\n",
    "def bm25_tokenizer(text):\n",
    "    tokenized_doc = []\n",
    "    for token in text.lower().split(): #(char): text.split()\n",
    "        token = token.strip(string.punctuation)\n",
    "\n",
    "        if len(token) > 0: # and token not in _stop_words.ENGLISH_STOP_WORDS\n",
    "            tokenized_doc.append(token) #.extend(list(token))       \n",
    "\n",
    "    return tokenized_doc\n",
    "\n",
    "tokenized_corpus = []\n",
    "for commit_message in remote_commits:\n",
    "    tokenized_doc = bm25_tokenizer(commit_message)\n",
    "    print(tokenized_doc)\n",
    "    tokenized_corpus.append(tokenized_doc)\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "tokenized_summary = bm25_tokenizer(summary)\n",
    "print(tokenized_summary)\n",
    "\n",
    " # BM25 search (lexical search)\n",
    "bm25_scores = bm25.get_scores(tokenized_summary)\n",
    "print(bm25_scores)\n",
    "\n",
    "top_n = numpy.argpartition(bm25_scores, -5)[-5:]\n",
    "bm25_hits = sorted([{'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n], key=lambda x: x['score'], reverse=True)\n",
    "for hit in bm25_hits[0:3]:\n",
    "    print(\"\\t{:.3f}\\t{}\".format(hit['score'], remote_commits[hit['corpus_id']].replace(\"\\n\", \" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use fusion for better results\n",
    "\n",
    "Now that we have a lists of Documents corresponding to different search results, they still could contain same documents. The idea is that if document is appeared in multiple retriever results it should be ranked higher, combining the scores, so that the nature and magnitude of score is preserved.\n",
    "\n",
    "To solve this issue Reciprocal Rank Fusion (RRF) scoring is typically used. RRF works by taking the search results from multiple methods, assigning a reciprocal rank score to each document in the results, and then combining the scores to create a new ranking. The score is calculated as `1/(rank + k)`, where `rank` is the position of the document in the list, and `k` is a constant, which was experimentally observed to perform best if it's set to a small value like `60`.\n",
    "\n",
    "Another idea is to assign a weight to each retriever, denoting the importance of corresponding query or source of data. The score of each document is multiplied by the weight of the retriever that returned it, contributing to the final score. Additionally, assuming that the rank depends on the position of document, you shouyld set a threshold for retrievers not to overrank not related documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.load import dumps, loads\n",
    "from typing import List\n",
    "\n",
    "weights =[0.5, 1]\n",
    "\n",
    "corpus = [commit.strip() for commit in remote_commits]\n",
    "kw_store = BM25Okapi([text.split() for text in corpus])\n",
    "in_memory_vector_store = InMemoryVectorStore(hfEmb)\n",
    "in_memory_vector_store.add_texts(corpus)\n",
    "\n",
    "def hybrid_search(query):\n",
    "    def kw_search(query, k=50): # add score threshold as parameter\n",
    "        kw_scores = kw_store.get_scores(query.split())\n",
    "        top_n = numpy.argpartition(kw_scores, -k)[-k:]\n",
    "        return sorted([(Document(corpus[idx]), kw_scores[idx]) for idx in top_n], key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return [kw_search(query, k=5), in_memory_vector_store.similarity_search_with_score(query, k=5)]\n",
    "\n",
    "def reciprocal_rank_fusion(results: List[List], k=60):\n",
    "    fused_scores = {}\n",
    "\n",
    "    for idx, docs in enumerate(results):\n",
    "        weight = weights[idx]\n",
    "        print(\"\\nSearch results \", idx)\n",
    "        for  doc, score in docs:\n",
    "            print(f\"[{score:.5f}]\\t{doc}\".replace(\"\\n\", \" \"))\n",
    "        for rank, doc in enumerate(docs):\n",
    "            rank = weight * rank\n",
    "            # Convert the document to a string format to use as a key or use document identifier\n",
    "            doc_str = dumps(doc[0].page_content)\n",
    "            # If the document is not yet in the fused_scores dictionary, add it with an initial score of 0\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "                \n",
    "            # Update the score of the document using the RRF formula: 1 / (rank + k)\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            fused_scores[doc_str] = previous_score + (1 / (rank + k))\n",
    "\n",
    "    # Sort the documents based on their fused scores in descending order to get the final reranked results\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # Return the reranked results as a list of tuples, each containing the document and its fused score\n",
    "    return reranked_results\n",
    "\n",
    "retrieval_chain_rag_fusion = (\n",
    "    RunnableLambda(hybrid_search)\n",
    "    | reciprocal_rank_fusion\n",
    ")\n",
    "\n",
    "result = retrieval_chain_rag_fusion.invoke(summary)\n",
    "\n",
    "print(\"\\nRRF fusion results:\")\n",
    "for doc, score in result:\n",
    "    print(f\"[{score:.5f}]\\t{doc}\".replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along with custom keyword search options we can use `git grep` that allows you to easily search through any committed tree, the working directory, or even the index for a string or regular expression.\n",
    "\n",
    "Hybrid search is also supported by some vendors like `Qdrant`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qdrant Hybrid Search\n",
    "# Git search and embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-rank combined results\n",
    "\n",
    "Now let's add some more data to one of the stores, so that the score is not consistent within sources. How do we deal with ranking in this case?\n",
    "\n",
    "Ranking results can be improved by applying semantic re-ranking, which is a technique that uses semantic similarity to get relevance of question to the answer to re-rank the search results.\n",
    "\n",
    "**ColBert** similarity ranking is based on token-level late interaction, that means that the query `q` is encoded into a multi-vector representation, and its similarity to a passage `d` is computed as the summation of query-side `MaxSim` operations, namely, the largest cosine similarity between *each query token* embedding and all passage token embeddings (https://arxiv.org/pdf/2112.01488).\n",
    "\n",
    "$$\n",
    "S_{q,d} = \\sum_{i=1}^{N} \\max_{j=1}^{M} \\mathbf{Q}_i \\cdot \\mathbf{D}_j^T\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# in_memory_vector_store.add_texts([doc.page_content for doc in commits_data])\n",
    "\n",
    "# Load the pre-trained ColBERT model and tokenizer (BERT-based)\n",
    "colbert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "colbert_model = BertModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
    "\n",
    "# Function to tokenize and encode text using ColBERT\n",
    "def colbert_tokenize(text):\n",
    "    return colbert_tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "def get_colbert_embeddings(text):\n",
    "    inputs = colbert_tokenize(text)\n",
    "    with torch.no_grad():\n",
    "        outputs = colbert_model(**inputs)\n",
    "    return outputs.last_hidden_state.squeeze(0)\n",
    "\n",
    "def colbert_score(query_embedding, doc_embedding):\n",
    "\n",
    "    # Normalize embeddings to calculate cosine similarity\n",
    "    query_embedding = torch.nn.functional.normalize(query_embedding, p=1)\n",
    "    doc_embedding = torch.nn.functional.normalize(doc_embedding, p=1)\n",
    "    \n",
    "    # Compute dot product (cosine similarity) between query and document tokens\n",
    "    # Shape: [N, M]\n",
    "    similarity_matrix = torch.matmul(query_embedding, doc_embedding.T)\n",
    "    \n",
    "    # For each query token, take the maximum similarity with any document token\n",
    "    # Shape: [N]\n",
    "    max_similarities = similarity_matrix.max(dim=1)[0]\n",
    "    \n",
    "    # Sum over all query tokens to get the final score\n",
    "    score = max_similarities.sum().item()\n",
    "    \n",
    "    return score\n",
    "\n",
    "def colbert_reranker(docs, summary):\n",
    "    query_embedding = get_colbert_embeddings(summary)\n",
    "    ranked_docs = []\n",
    "    for doc in docs:\n",
    "        # Compute document embeddings\n",
    "        doc_embedding = get_colbert_embeddings(doc)\n",
    "        \n",
    "        # Aggregate the token-level similarity score\n",
    "        score = colbert_score(query_embedding, doc_embedding)\n",
    "        \n",
    "        # Store the document and its re-ranking score\n",
    "        ranked_docs.append((doc, score))\n",
    "\n",
    "    return sorted(ranked_docs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "retrieval_chain_rerank = (\n",
    "    RunnableLambda(lambda summary: (hybrid_search(summary), summary))\n",
    "    | RunnableLambda(lambda results_summary: (reciprocal_rank_fusion(results_summary[0]), results_summary[1]))\n",
    "    | RunnableLambda(lambda results_summary: ([doc for doc, score in results_summary[0][:3]], results_summary[1]))\n",
    "    | RunnableLambda(lambda results_summary: colbert_reranker(*results_summary))\n",
    ")\n",
    "\n",
    "result = retrieval_chain_rerank.invoke(summary)\n",
    "\n",
    "print(\"\\nColBERT reranker results:\")\n",
    "for doc, score in result:\n",
    "    print(f\"[{score:.5f}]\\t{doc}\".replace(\"\\n\", \" \"))\n"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to apply Cross-Encoder to the search results to improve the ranking. In cross-encoder, the query and the document are concatenated and passed through a neural network to get the similarity score. The neural network is trained to predict whether the document is relevant to the query or not. The similarity score is used to rank the documents.\n",
    "\n",
    "![image-2.png](attachment:image-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "xenc_model = CrossEncoder(\"cross-encoder/ms-marco-TinyBERT-L-2\")\n",
    "\n",
    "def xenc_reranker(docs, summary):\n",
    "    model_inputs = [[summary, passage] for passage in docs]\n",
    "    scores = xenc_model.predict(model_inputs)\n",
    "    results = [(input[1], score) for input, score in zip(model_inputs, scores)]\n",
    "    \n",
    "    return sorted(results, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "retrieval_chain_rerank_x_enc = (\n",
    "    RunnableLambda(lambda summary: (hybrid_search(summary), summary))\n",
    "    | RunnableLambda(lambda results_summary: (reciprocal_rank_fusion(results_summary[0]), results_summary[1]))\n",
    "    | RunnableLambda(lambda results_summary: ([doc for doc, score in results_summary[0][:3]], results_summary[1]))\n",
    "    | RunnableLambda(lambda results_summary: xenc_reranker(*results_summary))\n",
    ")\n",
    "\n",
    "result = retrieval_chain_rerank_x_enc.invoke(summary)\n",
    "\n",
    "print(\"\\nColBERT reranker results:\")\n",
    "for doc, score in result:\n",
    "    print(f\"[{score:.5f}]\\t{doc}\".replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Ranking as an operation is also supported by services like `Cohere`.\n",
    "\n",
    "The whole process of hybrid search and reranking is available within multiple services, like `Azure AI Search`, `ElasticSearch`, `Quadrant`,  `Vespa`, `Pinecone`, etc, whit integraiton is also supported by `langchain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure AI Search Hybrid\n",
    "# Cohere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add filtering by metadata\n",
    "Filtering by metadata is a common use case in search engines, we can utilize any specific data store or database api to filter the data, or we can use `langchain` retrievers capabilities to filter the data based on metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter with self query filter\n",
    "# time-weighted retriever\n",
    "# get doc from chunks\n",
    "import os\n",
    "\n",
    "from qdrant_client import models\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "\n",
    "all_docs = js_docs + md_docs + other_docs + commit_docs\n",
    "\n",
    "file_list = [file.replace('/', os.path.sep) for file in get_changed_files()]\n",
    "print(file_list)\n",
    "\n",
    "all_docs_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"generic_collection_hf_384\",\n",
    "    embedding=hfEmb\n",
    ")\n",
    "all_docs_store.add_documents(all_docs)\n",
    "\n",
    "# {\"filter\": {\"source\": {\"$in\": file_list}}}\n",
    "# InMemoryVectorStore.from_documents(all_docs, openAIEmb) \n",
    "# Chroma.from_documents(other_docs, openAIEmb)\n",
    "\n",
    "results = all_docs_store.as_retriever().invoke(\"class AppTests\\n  def render_should_use_react_router\\n\")\n",
    "print(\"All results:\")\n",
    "print([doc.metadata['source'] for doc in results])\n",
    "\n",
    "results = all_docs_store.as_retriever(\n",
    "    search_kwargs={\"filter\": models.Filter(        \n",
    "        must=[\n",
    "            models.NestedCondition(\n",
    "                nested=models.Nested(\n",
    "                    key=\"metadata\",\n",
    "                    filter=models.Filter(\n",
    "                        must=[\n",
    "                            models.FieldCondition(key=\"source\",match=models.MatchAny(any=file_list)),\n",
    "                        ]\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "        ]) }).invoke(\"class AppTests\\n  def render_should_route_to_home\\n\")\n",
    "\n",
    "print(\"Recent results:\")\n",
    "print(results)\n",
    "\n",
    "# combine chunks\n",
    "# The vectorstore to use to index the child chunks\n",
    "# vectorstore = Chroma(collection_name=\"full_documents\", embedding_function=hfEmb)\n",
    "\n",
    "vectorstore = InMemoryVectorStore(hfEmb)\n",
    "store = InMemoryStore()\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=js_splitter,\n",
    ")\n",
    "\n",
    "retriever.add_documents(jsData, ids=None)\n",
    "\n",
    "results = retriever.invoke(\"class AppTests\\n  def render_should_route_to_home\\n\")\n",
    "\n",
    "print(\"Combined results:\")\n",
    "print(results)\n",
    "\n",
    "question = \"// create tests for new app feature\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to create a filter for the search results based on the query itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class CodeSearch(BaseModel):\n",
    "    code_search: str = Field(\n",
    "        ...,\n",
    "        description=\"The code search query\")\n",
    "    doc_search: str = Field(\n",
    "        ...,\n",
    "        description=\"The documentation and guidelines search query\"\n",
    "        \"Should be used to apply rules for certain type of code\")\n",
    "    language: str = Field(\n",
    "        ...,\n",
    "        description=\"The language of the code search query\")\n",
    "    source: str = Field(\n",
    "        ...,\n",
    "        description=\"The alias or wildcard of code file or library that can be related to a query\")\n",
    "    file_name: str = Field(\n",
    "        ...,\n",
    "        description=\"Possible name of a file or library that can be related to a query\")\n",
    "    updated_since: str = Field(\n",
    "        ...,\n",
    "        description=\"The date since the code was last updated\")\n",
    "    framework: str = Field(\n",
    "        ...,\n",
    "        description=\"The framework of the code search query\")\n",
    "    \n",
    "    def pretty_print(self) -> None:\n",
    "        for field in self.__fields__:\n",
    "            if getattr(self, field) is not None and getattr(self, field) != getattr(\n",
    "                self.__fields__[field], \"default\", None\n",
    "            ):\n",
    "                print(f\"{field}: {getattr(self, field)}\")\n",
    "\n",
    "system = \"\"\"You are an expert at converting user questions into database queries. \\\n",
    "You have access to a database of source code of a web service created for test purposes. \\\n",
    "Given a question, return a database query optimized to retrieve the most relevant code.\n",
    "\n",
    "If there are acronyms or words you are not familiar with, do not try to rephrase them.\n",
    "Today is october 2024\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "structured_llm = chat.with_structured_output(CodeSearch)\n",
    "query_analyzer = prompt | structured_llm\n",
    "\n",
    "filter = query_analyzer.invoke({\"question\": question})\n",
    "\n",
    "filter.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "\n",
    "def metadata_filter(filter):\n",
    "    field_filters = {\n",
    "        \"source\": lambda doc, value: fnmatch.fnmatch(doc.metadata.get(\"source\"), value),\n",
    "        \"file_name\": lambda doc, value: fnmatch.fnmatch(doc.metadata.get(\"file_name\"), value),\n",
    "        \"updated_since\": lambda doc, value: doc.metadata.get(\"updated_since\") > value,\n",
    "    }\n",
    "    def filter_doc(doc):\n",
    "        for key, value in filter.dict().items():\n",
    "            if value is not None and doc.metadata is not None and doc.metadata.get(key) is not None:\n",
    "                if key in field_filters:\n",
    "                    return field_filters[key](doc, value)\n",
    "                return doc.metadata.get(key) == value\n",
    "        return True\n",
    "\n",
    "    return filter_doc\n",
    "\n",
    "retriever.search_kwargs = {}\n",
    "results = retriever.invoke(question)\n",
    "print(\"Results:\")\n",
    "print(len(results))\n",
    "\n",
    "retriever.search_kwargs = {\"filter\": metadata_filter(filter)}\n",
    "\n",
    "results = retriever.invoke(question)\n",
    "print(\"Filtered results:\")\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it makes more sense not to filter out data based on timestamnps but rather update scoring of the search result, so that data is not lost but ranked accordingly. For example, langchain time-weighted vector store retriever uses a combination of semantic similarity and a time decay.\n",
    "\n",
    "```\n",
    "semantic_similarity + (1.0 - decay_rate) ^ hours_passed\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time-weighted vector store\n",
    "\n",
    "import datetime\n",
    "import random\n",
    "import faiss\n",
    "from langchain_community.docstore import InMemoryDocstore\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.utils import mock_now\n",
    "\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "faiss_vectorstore = FAISS(openAIEmb, index, InMemoryDocstore({}), {})\n",
    "faiss_vectorstore.add_documents(md_docs)\n",
    "\n",
    "result = faiss_vectorstore.similarity_search_with_score(\"How to use React Router\", k=5)\n",
    "\n",
    "print(\"Similarity search results:\")\n",
    "for doc, score in result:\n",
    "    print(f\"[{score:.5f}]\\t{doc.page_content}\".replace(\"\\n\", \" \"))\n",
    "\n",
    "for doc in md_docs:\n",
    "    random_days = random.randint(0, 6)\n",
    "    random_seconds = random.randint(0, 86399)  # 86399 seconds in a day\n",
    "    random_time_delta = datetime.timedelta(days=random_days, seconds=random_seconds)\n",
    "    doc.metadata[\"last_accessed_at\"] = datetime.datetime.now() - random_time_delta\n",
    "\n",
    "retriever = TimeWeightedVectorStoreRetriever(\n",
    "    vectorstore=faiss_vectorstore,\n",
    "# high decay rate, the recency score quickly goes to 0. If you set this all the way to 1, recency is 0 for all objects, making this equivalent to a vector lookup.\n",
    "    decay_rate=0.999,\n",
    "# low decay rate means memories will be \"remembered\" for longer. A decay rate of 0 means memories never be forgotten, making this equivalent to a vector lookup.\n",
    "    #decay_rate=0.0000000000000000000000001,\n",
    "    k=5\n",
    ")\n",
    "\n",
    "retriever.add_documents(md_docs)\n",
    "result = retriever.invoke(\"How to use React Router\")\n",
    "\n",
    "print(\"\\nSearch with time weighting:\")\n",
    "for doc in result:\n",
    "    print(f\"[{doc.metadata['updated_since']}]\\t{doc.page_content}\".replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routing for different sources\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Data model\n",
    "class RouteQuery(BaseModel):\n",
    "    datasource: Literal[\"python_docs\", \"js_docs\", \"csharp_docs\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose which datasource would be most relevant for answering their question\",\n",
    "    )\n",
    "\n",
    "route_llm = chat.with_structured_output(RouteQuery)\n",
    "\n",
    "system = \"\"\"You are an expert at routing a user question to the appropriate data source.\n",
    "\n",
    "Based on the programming language the question is referring to, route it to the relevant data source.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define router \n",
    "router = prompt | route_llm\n",
    "\n",
    "question = \"\"\"Why doesn't the following code work:\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\"human\", \"speak in {language}\"])\n",
    "prompt.invoke(\"french\")\n",
    "\"\"\"\n",
    "\n",
    "result = router.invoke({\"question\": question})\n",
    "\n",
    "print(\"Route result:\", result.datasource)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data retrieval appears more complicated when we are trying to find the most relevant data based on the input. You can follow these concepts when working with langchain stack here https://python.langchain.com/docs/concepts/#retrieval "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt\n",
    "The final prompt will be a combination of the context and the query. Its structure is strongly dependent on the use case, the data we have and LLM that is used. For example for completions we can use special purpose **Stable Code** models that will require quite strict structure of the prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it can be useful to apply defferent prompts depending on the context of the search, for example if we are looking for a code completion we can use a prompt that will be more specific to the certain code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "# Prompt selection based on the context\n",
    "js_template = \"\"\"You are JS sxpert and should be able to write tests for the code snippet. Consider the following example:\n",
    "Code snippet:\n",
    "```\n",
    "class Calculator {\n",
    "    add(a, b) {\n",
    "        return a + b;\n",
    "    }\n",
    "}\n",
    "```\n",
    "Correct output:\n",
    "class CalculatorTests {\n",
    "    @Test\n",
    "    public void testAdd() {\n",
    "        var calculator = new Calculator();\n",
    "        assertEquals(5, calculator.add(2, 3));\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "cs_template = \"\"\"You are C# sxpert and should be able to write tests for the code snippet. Consider the following example:\n",
    "Code snippet:\n",
    "```\n",
    "public class Calculator {\n",
    "    public int Add(int a, int b) => a + b;\n",
    "}\n",
    "```\n",
    "Correct output:\n",
    "[TextFixture]\n",
    "class CalculatorTests {\n",
    "\n",
    "    [TestCase(2, 3, 5)]    \n",
    "    [TestCase(0, -1, -1)]\n",
    "    public void testAdd(int a, int b, int expected) {\n",
    "        var calculator = new Calculator();\n",
    "\n",
    "        Assert.AreEqual(expected, calculator.Add(a, b));\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "prompt_templates = [js_template, cs_template]\n",
    "prompt_embeddings = openAIEmb.embed_documents(prompt_templates)\n",
    "\n",
    "def prompt_router(input):\n",
    "    code_snippet = input[\"code\"]\n",
    "\n",
    "    # Embed question\n",
    "    query_embedding = openAIEmb.embed_query(code_snippet)\n",
    "\n",
    "    # Compute similarity\n",
    "    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\n",
    "    most_similar = prompt_templates[similarity.argmax()]\n",
    "\n",
    "    # Chosen prompt \n",
    "    print(\"Selected Lang:\", most_similar == js_template and \"JS\" or \"C#\")\n",
    "\n",
    "    input[\"system\"] = most_similar\n",
    "\n",
    "    return ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"{system}\"),\n",
    "        (\"user\", \"Create tests for the following code:\\n{code}\\n PROVIDE ONLY CODE AND NOTHING ELSE\"),\n",
    "    ])\n",
    "\n",
    "chain = (\n",
    "    {\"code\": RunnablePassthrough()}\n",
    "    | RunnableLambda(prompt_router)\n",
    "    | chat\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke(\"\"\"class App {\n",
    "    public void render() {\n",
    "        return <div>App</div>;\n",
    "    }\n",
    "}\n",
    "\"\"\"))\n",
    "\n",
    "print(chain.invoke(\"\"\"public class HomeController {\n",
    "    public IActionResult Index(string path)\n",
    "    {\n",
    "        if (string.IsNullOrEmpty(path))\n",
    "        {\n",
    "            return NotFound();\n",
    "        }\n",
    "        return View();\n",
    "    }\n",
    "}\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIM prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi modal input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphRAG\n",
    "https://microsoft.github.io/graphrag/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Completions\n",
    "LSP Completions - https://github.com/microsoft/language-server-protocol/blob/gh-pages/_specifications/lsp/3.18/language/completion.md\n",
    "Continue.Dev custom RAG - https://docs.continue.dev/customize/tutorials/custom-code-rag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
